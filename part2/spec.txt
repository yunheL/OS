===pin process to core===
before conducting the following experiments, need to pin process to core.
use ps -aF to make sure process on specific core.

===rdtsc() spec===
run rdtsc 1 billion times. Divide the number of ticks over 1 billion to average out timing time cost so that we can get the time of running one rdtsc(). When we are doing this, we also made sure that the process we are running is pinned to a specific core.

run this experiment in loop for 100 times, record the max, min and average. In order compare whether rdtsc() takes a consistent amount of time to run. 

It turned out that rdtsc() does take a relatively consistent amount of time to run. Here is the max, min and avg timing of these 100 loops:

1st run
max: 21.769140 ticks
min: 21.468231 ticks
avg: 21.562288 ticks

2nd run
max: 21.963270 ticks
min: 21.471663 ticks
avg: 21.517359 ticks

3rd run
max: 21.775490 ticks
min: 21.421061 ticks
avg: 21.499767 ticks

===clock_gettime() spec===
run clock_gettime() for 1 billions, divide the time elapsed by 1 billion. Do this in loop for 50 times, record max, min and average.

1st run
max: 15.784463 ns
min: 15.369225 ns
avg: 15.470197 ns

2nd run
max: 16.028545 ns
min: 15.367361 ns
avg: 15.441755 ns

3rd run
max: 15.714920 ns
min: 15.371749 ns
avg: 15.423429 ns

===socket===

---latency---
1. set flags TCP_NODELAY, SO_REUSEADDR
2. remove other operating between read and write so that we are not timing anything else than latency, especially the print statement, saved lots of time
3. generate payload to fulfill the length requirement
4. pined process to a specific CPU in order to use rdtsc();
4. record max, min and avg. It looks like using min would make the most sense.
5. results of latency. Running each msg size of 100,000 times
6. created clock_client to record time use clock_gettime() and record time in ns. Looks like the result from clock_gettime() matches the result from rdtsc().
7.realized that the size of msg() that read and write might not be the size as you specified as the size goes up.
8. you also want to make sure the server is sending back the same msg so that round trip time make sense. 
9. Also you want the server to send back msg with the same size so that the round trip time actually make sense. 
10. "Transmission times can be affecting in TCP by the MTU (maximum transmission unit) size (typically 1500 bytes) and read and write buffer sizes (typically 128KB. If you have root access to a Linux system, you can experiment with increasing these sizes. Of course, you will not be allowed to do that on the instructional Linux systems. "
11. put the write and read in a loop to ensure the length of msg is desired.
12. made sure to divide the round trip time by 2
13. also made sure that the client and server program are running on two different cores.
14. make sure all the units are B/us, which has the same value of MB/s
15. way to determin the number of iternations is to see whether the result from each time is fairly stable, and also, changing into a larger number won't really gave us a short min time.
16. an obervation is that the avg value gets pretty stable with NUMLOOPs hit 10^4 but the min would get stable until 10^7

size = 4
run 10000000 cycles, length is 4, first 4 char: abcd
max: 38868544 ticks, 12165.854272 us
min: 24684 ticks, 7.726092 us
avg: 51191.064663 ticks, 16.022803 us

size = 16
run 10000000 cycles, length is 16, first 4 char: abcd
max: 37279366 ticks, 11668.441558 us
min: 25616 ticks, 8.017808 us
avg: 51260.274445 ticks, 16.044466 us

run 10000000 cycles, length is 64, first 4 char: abcd
max: 40900030 ticks, 12801.709390 us
min: 25291 ticks, 7.916083 us
avg: 51432.047803 ticks, 16.098231 us

run 10000000 cycles, length is 256, first 4 char: abcd
max: 43181143 ticks, 13515.697759 us
min: 25975 ticks, 8.130175 us
avg: 51253.569981 ticks, 16.042367 us

run 10000000 cycles, length is 1024, first 4 char: abcd
max: 43298263 ticks, 13552.356319 us
min: 25451 ticks, 7.966163 us
avg: 52762.593741 ticks, 16.514692 us

---throughput---
1. use a counter to keep track of the number of bytes being sent


===using PERF and strace===
---PERF---
perf record + your own program
perf report

---strace---
strace -ttT + your own program

===todo on Tuesday night===
1. finish up experiment
2. figure out performance
3. record video for part1
4. write paper for part2 

===Tuesday left off===
1. experimenting with latency finished size of 4, 16, 64, 256, 1k
2. todos within experiment: finish latency, modify throughput code to make
it situable for experiment (build shell script for through put experiments as well)
3. finish throughput code
4. maybe want to distributed work to multiple machines especially those needs longer times 

===point to make sure===
1. 3 type of average. arthimatic, harmonic and geometric.
2. "If the processor can automatically vary the clock speed, the timestamp counter may not reflect real time." Make sure processor don't vary clock speed.
3. "You can only compare values on a single core and not across cores." Make sure process is running on a single core.
4. 2 mechanism, highest resolution.
5. simple loop experiment.
6. confirm redtsc() accuracy with clock_gettime().

===Sunday left off===
1. finished 4-256 latency timing for socket
2. To do for socket, throughput and latency with msg size > 256
3. Working on the "where did the time go part"
4. Starting writing paper
